disqontrol:
    # The log directory
    # Default value: /var/log/disqontrol
    #
    # If the path is relative, it is relative to the configuration file.
    log_dir: /var/log/disqontrol

    # The cache directory
    # Default value: /tmp/disqontrol
    #
    # If the path is relative, it is relative to the configuration file.
    cache_dir: /tmp/disqontrol

    # The initial connection to Disque
    # The order of nodes doesn't matter, we connect to a random one
    # as recommended by Disque
    disque:
        # Node 1
        - host: '127.0.0.1'
          port: 7711

        # Node 2 with a password
        - host: '127.0.0.1'
          port: 7712
          password: 'foo'

    # Defaults for all queues. Each queue can set its own values, too.
    queue_defaults:
        # How long can a job be processed before timing out (in seconds)?
        # Default value: 600
        # Disque argument name: RETRY
        #
        # If you plan to run jobs that take longer than 10 minutes, adjust
        # the maximum process time here or for the particular queue.
        # Otherwise the jobs will be automatically returned to the queue as
        # timed out.
        #
        # If you set this to 0, the job will be delivered at most once.
        job_process_timeout: 600

        # How long can a job wait in the queue before getting automatically
        # deleted (in seconds)?
        # Default value: 172800
        # Disque argument name: TTL
        #
        # If the job lies unprocessed longer than this, it is automatically
        # deleted. If you have jobs that you schedule in advance more than
        # 48 hours, increase this value so they are not purged before they're
        # up.
        #
        # The maximum allowed value is 3932100 seconds, or about 45,5 days.
        #
        # @see function generateJobID() in
        # https://github.com/antirez/disque/blob/master/src/job.c
        job_lifetime: 172800

        # What failure strategy should be used for handling a failed job?
        # Default value: retry
        #
        # Possible values:
        # retry
        # - Retry the failed job with an exponential backoff, ie. the job will
        #   be returned to the queue with an ever longer delay
        #
        # retry_immediately
        # - Retry the failed job immediately, until the job runs out of allowed
        #   retries.
        failure_strategy: retry

        # How many times a failed job should be retried before we give up
        # and move it to a failure queue (a dead letter queue).
        # Default value: 25
        max_retries: 25

        # Where should completely failed jobs go?
        # Default value: 'failed-jobs'
        failure_queue: 'failed-jobs'

    # Configuration of queues and their workers
    queues:
        # The key ("registration-email") is also the queue name in Disque
        # That is what you use as a queue name when adding a new job
        #
        # The name of the queue is used both as a YAML key as well as a PHP
        # array key. Thus it must conform to both specifications.
        #
        # If the queue name contains any of the following characters, wrap it
        # in single quotes:
        # :, {, }, [, ], ,, &, *, #, ?, |, -, <, >, =, !, %, @, \`
        #
        # @see http://symfony.com/doc/current/components/yaml/yaml_format.html#strings
        'registration-email':

            # An example of a command-line worker called via a console command
            worker:
                # The "type" determines the worker type.
                #
                # Allowed worker call types are
                # - command            : A console command
                # - http               : A HTTP request
                # - inline_php_worker  : An inline PHP call
                # - isolated_php_worker: A PHP worker wrapped in a console command
                #
                # All workers but inline PHP workers allow asynchronous calls.
                # (See the comment at 'job_batch' below.)
                #
                # The other required parameter is the worker target:
                # Its address/command/name.
                #
                # You can use any of these three keys to define the worker target:
                # - address:
                # - command:
                # - name:
                #
                # In case of a console command, it is the command itself.
                type: command

                # The target for this worker - its command:
                command: 'php console email:send'
                
                # Console commands are called with the arguments:
                # "--queue=" followed by the queue name
                # "--body=" followed by a JSON-serialized job body.
                # "--metadata=" followed by JSON-serialized job metadata
                #
                # The exact command for this worker would be:
                # php console email:send --queue='registration-email' --body=... --metadata=...

            # You can override the queue defaults defined above
            job_process_timeout: 10
            job_lifetime: 3600
            failure_strategy: retry_immediately
            max_retries: 5
            failure_queue: 'unsent-registration-emails'

        # This is another queue
        'profile-update':

            # An example of an HTTP worker (a worker called via a HTTP request)
            # There are two allowed request methods, POST and GET.
            #
            # POST requests have the content type set to
            # application/x-www-form-urlencoded
            # The job body and metadata are sent in the POST request body
            # under parameters 'body' and 'metadata' serialized as JSON.
            #
            # POST body example: body=...&metadata=...
            #
            # GET requests have parameters 'body' and 'metadata' added to the URI,
            # also serialized as JSON.
            #
            # GET URI example: https://example.com/worker?body=...&metadata=...
            #
            # If you are using the GET method to send a longer job body over
            # the network, beware of the target webserver's limitation
            # regarding the URL length.
            worker:

                # The worker type and address
                type: http
                address: 'https://example.com/worker?key={api_key}'

                # TODO: The request method of the worker HTTP call.
                #
                # Allowed values: post, get
                # Default value: 'post'
                #method: 'post'

                # Optional headers
                #headers:
                #    'Content-Type': 'application/json'

                # More optional parameters. The key is up to you
                #api_key: 'foobar123'
                #another_parameter: 'baz'

        'pic-resize':
            # An example of an inline PHP worker called directly in the consumer.
            # It's actually the Consumer process that processes the jobs, so
            # beware of memory leaks.
            # Create a WorkerFactory for each PHP worker and register it during
            # the Disqontrol bootstrap.
            worker:
                type: inline_php_worker
                name: 'pic_resize_worker'

        'rss-update':
            # An example of a PHP worker wrapped in a console command
            # You could just as well write your own console command in PHP,
            # this is a convenient helper so that it's enough just to write
            # one class.
            # This worker processes just one job and exits. Thus there's no
            # worry about memory leaks.
            # Create a WorkerFactory for each isolated PHP worker and register
            # them during the Disqontrol bootstrap.
            worker:
                type: isolated_php_worker
                name: 'rss_update_worker'

    # Default settings for all consumers
    consumer_defaults:
        # The minimum (and default) number of processes each consumer will run
        # Default value: 1
        min_processes: 1

        # The maximum number of processes each consumer can automatically scale up to
        # Default value: 5
        max_processes: 5

        # Scale up the number of consumer processes automatically?
        # Default value: true
        autoscale: true

        # The maximum number of jobs processed in one consumer in one batch
        # Default value: 10
        #
        # The consumer will ask Disque for a batch of as many jobs as specified
        # here and if possible (for workers that allow asynchronous calls, i.e.
        # HTTP, command-line and isolated PHP workers) calls all workers in the batch at once.
        job_batch: 10

    # Define consumers
    #
    # This whole section is optional. Each queue that doesn't have its own
    # consumer defined here will get its own dedicated consumer
    # with the default values. If you begin and don't yet know the performance
    # profile of your queues, you can leave the whole section empty.
    consumers:

